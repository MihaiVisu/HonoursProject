{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "%matplotlib inline\n",
    "\n",
    "# import used packages and modules\n",
    "# import display function to display the table of the pandas dataframe\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.model_selection import LeaveOneOut, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "from hmmlearn import hmm\n",
    "from seqlearn.hmm import MultinomialHMM\n",
    "\n",
    "import datetime\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import csv\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_manchester = pd.read_csv('../data/misc/Train_Manchester_Northwich.csv')\n",
    "london_data = pd.read_csv('../data/london_data/london_data.csv')\n",
    "\n",
    "data04 = pd.read_csv('../data/meadows_december/meadows-2017-12-04.csv')\n",
    "data05 = pd.read_csv('../data/meadows_december/meadows-2017-12-05.csv')\n",
    "\n",
    "bike_data_old = pd.read_csv('../data/misc/2015061911.csv')\n",
    "bike_data_feb = pd.read_csv('../data/misc/bike_feb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bin_vals = ['bin'+str(x) for x in range(0,16)]\n",
    "pm_vals = ['pm1', 'pm2_5', 'pm10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# environment index is 0 as all data from these datasets is walking data\n",
    "data04['environment_index'] = 0\n",
    "data05['environment_index'] = 0\n",
    "\n",
    "# environment index is 3 for bike data\n",
    "bike_data_old['environment_index'] = 3\n",
    "bike_data_feb['environment_index'] = 3\n",
    "\n",
    "# add more bus data to balance dataset\n",
    "# bus_data = london_data[london_data['environment_index'] == 4]\n",
    "# bus_data = pd.concat([bus_data]*2, ignore_index=True)\n",
    "\n",
    "labels = bin_vals + pm_vals + ['environment_index', 'gpsLatitude', 'gpsLongitude', 'humidity']\n",
    "\n",
    "data = pd.concat([london_data[labels],\n",
    "#                   bus_data[labels],\n",
    "                  train_manchester[labels], \n",
    "                  data04[labels], \n",
    "                  data05[labels], \n",
    "                  bike_data_old[labels],\n",
    "                  bike_data_feb[labels]], ignore_index=True)\n",
    "\n",
    "# remove indoor labelled data for this set of experiments\n",
    "data = data[data['environment_index']!=7]\n",
    "data = data[data['environment_index']!=5]\n",
    "data = data[data['humidity']>0]\n",
    "# data = data[data['environment_index']!=4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_idx = np.array([0, 1, 2, 3, 4, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# method to get the cluster means of the data points based on coordinates\n",
    "# and the queried columns\n",
    "def get_location_cluster_means(data, cluster_no, cols):\n",
    "    # obtain indices of clusters\n",
    "    kmeans = KMeans(n_clusters=cluster_no, random_state=0)\n",
    "    # remove data rows with null coordinates\n",
    "    data = data[~np.isnan(data['gpsLatitude'])]\n",
    "    # get the indices of the location based clusters\n",
    "    indices = kmeans.fit_predict(data[['gpsLatitude', 'gpsLongitude']])\n",
    "    freqs = np.bincount(indices)\n",
    "    # initialise means of queried columns\n",
    "    means = np.zeros((cluster_no, len(cols)))\n",
    "    # assign clustered_indices to dataframe\n",
    "    data['clustered_index'] = indices\n",
    "    # compute means of queried columns\n",
    "    for index in np.unique(indices):\n",
    "        means[index] = np.mean(data[data['clustered_index'] == index][cols])\n",
    "    return means, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# method to get the clusters of the environments corresponding to the 5 environments based on\n",
    "# the queried columns and number of location clusters\n",
    "def get_environment_clusters(data, cluster_no, cols):\n",
    "    means, d = get_location_cluster_means(data, cluster_no, cols)\n",
    "    # we have 5 clusters corresponding to 6 different types of transport\n",
    "    environment_kmeans = KMeans(n_clusters=6, random_state=0)\n",
    "    # predict the cluster indices\n",
    "    environment_indices = environment_kmeans.fit_predict(means)\n",
    "    # sort the indices based on the means of the clusters\n",
    "    idx = np.argsort(environment_kmeans.cluster_centers_.sum(axis=1))\n",
    "    lut = np.zeros_like(idx)\n",
    "    lut[idx] = np.arange(6)\n",
    "    # append the indices to the dataframe\n",
    "    d['unsupervised_environment_index'] = lut[environment_indices][d['clustered_index']]\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(labels, predictions, title='Confusion matrix'):\n",
    "    \"\"\"Plots a confusion matrix.\"\"\"\n",
    "    cmatrix = np.array(confusion_matrix(labels, predictions))\n",
    "    # normalize confusion matrix\n",
    "    cm = cmatrix/cmatrix.sum(axis=1)[:, np.newaxis]\n",
    "    classes=['on_foot', 'car', 'train', 'bike', 'underground']\n",
    "    if classes is not None:\n",
    "        sns.heatmap(cm, xticklabels=classes, yticklabels=classes, vmin=0., vmax=1., annot=True)\n",
    "    else:\n",
    "        sns.heatmap(cm, vmin=0., vmax=1.)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True data')\n",
    "    plt.xlabel('Predicted data')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_training_accuracy_with_kfolds_iloc(estimator, x_tr, y_tr, kf):\n",
    "    score_array = np.empty(kf.n_folds)\n",
    "    \n",
    "    for (idx, (train_feature, test_feature)) in enumerate(kf):\n",
    "        estimator.fit(x_tr.iloc[train_feature], y_tr.iloc[train_feature])\n",
    "        y_pred = estimator.predict(x_tr.iloc[test_feature])\n",
    "        cm = confusion_matrix(y_tr.iloc[test_feature], y_pred)\n",
    "        cm_norm = cm.astype('float')/cm.sum(axis=1)\n",
    "        score_array[idx] = accuracy_score(y_tr.iloc[test_feature], y_pred, normalize=True)\n",
    "        \n",
    "#         plot_confusion_matrix(y_tr.iloc[test_feature], y_pred)\n",
    "        \n",
    "    return np.mean(score_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_training_accuracy_mixed_models(estimators, x_tr, y_tr, kf):\n",
    "    score_array = np.empty(kf.n_folds)\n",
    "    \n",
    "    for (idx, (train_feature, test_feature)) in enumerate(kf):\n",
    "        probs_array = np.empty((len(estimators), x_tr.iloc[test_feature].shape[0], 6))\n",
    "\n",
    "        for estimator_idx, estimator in enumerate(estimators):\n",
    "            estimator.fit(x_tr.iloc[train_feature], y_tr.iloc[train_feature])\n",
    "            probs_array[estimator_idx] = estimator.predict_proba(x_tr.iloc[test_feature])\n",
    "        \n",
    "        final_labels = labels_idx[np.argmax(np.mean(probs_array, axis=0), axis=1)]\n",
    "        score_array[idx] = accuracy_score(y_tr.iloc[test_feature], final_labels, normalize=True)\n",
    "    \n",
    "    return np.mean(score_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.932007674865\n"
     ]
    }
   ],
   "source": [
    "clustered_data = get_environment_clusters(data, 40, bin_vals)\n",
    "\n",
    "clustered_normalised_data = clustered_data[clustered_data['bin0']>0].copy().reindex()\n",
    "clustered_normalised_data[bin_vals] = clustered_normalised_data[bin_vals].apply(lambda row: row/np.sum(row), axis=1)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0, n_estimators=260, n_jobs=-1)\n",
    "kf = KFold(len(clustered_normalised_data), n_folds=5, shuffle=True, random_state=0)\n",
    "\n",
    "print(\"Accuracy:\", get_training_accuracy_with_kfolds_iloc(rf, clustered_normalised_data[['unsupervised_environment_index', 'humidity']+bin_vals], \n",
    "                                                          clustered_normalised_data['environment_index'], kf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing bus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.941718865338\n"
     ]
    }
   ],
   "source": [
    "filtered_data = data[data['environment_index']!=4]\n",
    "clustered_data = get_environment_clusters(filtered_data, 40, bin_vals)\n",
    "\n",
    "clustered_normalised_data = clustered_data[clustered_data['bin0']>0].copy().reindex()\n",
    "clustered_normalised_data[bin_vals] = clustered_normalised_data[bin_vals].apply(lambda row: row/np.sum(row), axis=1)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0, n_estimators=260, n_jobs=-1)\n",
    "kf = KFold(len(clustered_normalised_data), n_folds=5, shuffle=True, random_state=0)\n",
    "\n",
    "print(\"Accuracy:\", get_training_accuracy_with_kfolds_iloc(rf, clustered_normalised_data[['unsupervised_environment_index', 'humidity']+bin_vals], \n",
    "                                                          clustered_normalised_data['environment_index'], kf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Underground Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.941346439291\n"
     ]
    }
   ],
   "source": [
    "filtered_data = data[data['environment_index']!=6]\n",
    "\n",
    "clustered_data = get_environment_clusters(filtered_data, 40, bin_vals)\n",
    "\n",
    "clustered_normalised_data = clustered_data[clustered_data['bin0']>0].copy().reindex()\n",
    "clustered_normalised_data[bin_vals] = clustered_normalised_data[bin_vals].apply(lambda row: row/np.sum(row), axis=1)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0, n_estimators=260, n_jobs=-1)\n",
    "kf = KFold(len(clustered_normalised_data), n_folds=5, shuffle=True, random_state=0)\n",
    "\n",
    "print(\"Accuracy:\", get_training_accuracy_with_kfolds_iloc(rf, clustered_normalised_data[['unsupervised_environment_index', 'humidity']+bin_vals], \n",
    "                                                          clustered_normalised_data['environment_index'], kf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.864460095632\n"
     ]
    }
   ],
   "source": [
    "# environment clustering on raw bin values: 3 hidden layers\n",
    "clustered_data = get_environment_clusters(data, 40, bin_vals)\n",
    "\n",
    "clustered_normalised_data = clustered_data[clustered_data['bin0']>0].copy().reindex()\n",
    "clustered_normalised_data[bin_vals] = clustered_normalised_data[bin_vals].apply(lambda row: row/np.sum(row), axis=1)\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', \n",
    "                    alpha=1e-5, \n",
    "                    hidden_layer_sizes=(20,), \n",
    "                    random_state=1, \n",
    "                    max_iter=500)\n",
    "kf = KFold(len(clustered_normalised_data), n_folds=3, shuffle=True, random_state=0)\n",
    "\n",
    "print(\"Accuracy:\", get_training_accuracy_with_kfolds_iloc(clf, clustered_normalised_data[['unsupervised_environment_index']+bin_vals], \n",
    "                                                          clustered_normalised_data['environment_index'], kf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92384338350724904"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(len(clustered_normalised_data), n_folds=5, shuffle=True, random_state=0)\n",
    "\n",
    "get_training_accuracy_mixed_models([clf, rf, rf2], clustered_normalised_data[['unsupervised_environment_index', 'humidity']+bin_vals], \n",
    "                                                          clustered_normalised_data['environment_index'], kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
